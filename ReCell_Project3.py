# -*- coding: utf-8 -*-
"""SLF_Project_LearnerNotebook_FullCode-JoannaSalvucci.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1DEXIF_dAJZs1GPQQ4M1AmPCm_6YmR9G7

# Supervised Learning - Foundations Project: ReCell

## Problem Statement

### Business Context

Buying and selling used phones and tablets used to be something that happened on a handful of online marketplace sites. But the used and refurbished device market has grown considerably over the past decade, and a new IDC (International Data Corporation) forecast predicts that the used phone market would be worth \\$52.7bn by 2023 with a compound annual growth rate (CAGR) of 13.6% from 2018 to 2023. This growth can be attributed to an uptick in demand for used phones and tablets that offer considerable savings compared with new models.

Refurbished and used devices continue to provide cost-effective alternatives to both consumers and businesses that are looking to save money when purchasing one. There are plenty of other benefits associated with the used device market. Used and refurbished devices can be sold with warranties and can also be insured with proof of purchase. Third-party vendors/platforms, such as Verizon, Amazon, etc., provide attractive offers to customers for refurbished devices. Maximizing the longevity of devices through second-hand trade also reduces their environmental impact and helps in recycling and reducing waste. The impact of the COVID-19 outbreak may further boost this segment as consumers cut back on discretionary spending and buy phones and tablets only for immediate needs.


### Objective

The rising potential of this comparatively under-the-radar market fuels the need for an ML-based solution to develop a dynamic pricing strategy for used and refurbished devices. ReCell, a startup aiming to tap the potential in this market, has hired you as a data scientist. They want you to analyze the data provided and build a linear regression model to predict the price of a used phone/tablet and identify factors that significantly influence it.


### Data Description

The data contains the different attributes of used/refurbished phones and tablets. The data was collected in the year 2021. The detailed data dictionary is given below.


- brand_name: Name of manufacturing brand
- os: OS on which the device runs
- screen_size: Size of the screen in cm
- 4g: Whether 4G is available or not
- 5g: Whether 5G is available or not
- main_camera_mp: Resolution of the rear camera in megapixels
- selfie_camera_mp: Resolution of the front camera in megapixels
- int_memory: Amount of internal memory (ROM) in GB
- ram: Amount of RAM in GB
- battery: Energy capacity of the device battery in mAh
- weight: Weight of the device in grams
- release_year: Year when the device model was released
- days_used: Number of days the used/refurbished device has been used
- normalized_new_price: Normalized price of a new device of the same model in euros
- normalized_used_price: Normalized price of the used/refurbished device in euros

## Importing necessary libraries
"""

#libraries for reading and manipulating data
import numpy as np
import pandas as pd

#libraries for data visualization
import matplotlib.pyplot as plt
import seaborn as sns

sns.set()

#splitting data into train and test set
from sklearn.model_selection import train_test_split

#build linear regression model
import statsmodels.api as sm

#to check model performance
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score

"""## Loading the dataset"""

#mount google drive and load dataset
from google.colab import drive
drive.mount('/content/drive')
data = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/PGP Module 3 Week 2 & Proj/used_device_data.csv')

#create a copy to avoid changes to the original dataset
devices = data.copy()

"""## Data Overview

- Observations
- Sanity checks
"""

#view the first and last 5 rows of the dataset
devices.head()

devices.tail()

"""The dataframe has been loaded properly."""

devices.shape #check the number of rows and columns in the dataset

"""The dataframe includes 3,454 rows (devices) and 15 columns (attributes)."""

devices.info() #check datatypes of the columns in the dataset

"""Four columns in the dataset include categorical or "object" datatypes (brand_name, os, 4g, and 5g) and the remaining 11 columns are numerical - either float or integer datatypes. The target variable is the normalized_used_price, which is float datatype."""

devices.describe(include='all').T #check statistical summary

"""Observations:

Numerical columns:

- The screen size column has a mean of 13.7 cm and a standard deviation of 3.8 cm. The 25th and 50th percentile are close to each other and there seems to be a large range (5.08 to 30.71 cm).

- The main camera and selfie camera have comparable resolutions in megapixels, however the main cameras tend to have slightly higher resolution. The selfie camera has a mean of 6.55 megapixels and the main camera has a mean of 9.46 megapixels.

- The int_memory column has an average of around 55 GB and a larger standard deviation of around 85. This column also has a large range, from 0.01 to over 1000.

- The ram column has the same value (4 GB) for the 25th, 50th, and 75th percentile.

- The battery and weight columns seem right-skewed based on the max/min values and interquartile range. Although, we will need to confirm this through further analysis.

- The release_year ranges from 2013 to 2020, and the days_used column ranges from 91 to 1094 with an average of 674 days.

- The normalized_new_price and normalized_used_price columns differ in min/max and interquartile range values by roughly 1 euro. The 25th, 50th, and 75th percentile is close in the used price column.

Categorical columns:
- There are 34 unique brand names of which the top is "Others" (502 devices).

- There are 4 different OS values of which the top is Android (3214 devices).

- 4g and 5g columns represent whether 4g or 5g is available, and therefore each have two unique values (yes and no). The 4g column has more yes values (2335) and the 5g column has more no values (3302).
"""

devices.isnull().sum() #count the number of null values in each column

"""There appear to be missing values in 6 columns, with the main_camera_mp having the most missing values (179)."""

devices.duplicated().sum() #print the number of duplicated columns in the dataset

"""There are no duplicate values in the dataset.

## Exploratory Data Analysis (EDA)

- EDA is an important part of any project involving data.
- It is important to investigate and understand the data better before building a model with it.
- A few questions have been mentioned below which will help you approach the analysis in the right manner and generate insights from the data.
- A thorough analysis of the data, in addition to the questions mentioned below, should be done.

**Questions**:

1. What does the distribution of normalized used device prices look like?
2. What percentage of the used device market is dominated by Android devices?
3. The amount of RAM is important for the smooth functioning of a device. How does the amount of RAM vary with the brand?
4. A large battery often increases a device's weight, making it feel uncomfortable in the hands. How does the weight vary for phones and tablets offering large batteries (more than 4500 mAh)?
5. Bigger screens are desirable for entertainment purposes as they offer a better viewing experience. How many phones and tablets are available across different brands with a screen size larger than 6 inches?
6. A lot of devices nowadays offer great selfie cameras, allowing us to capture our favorite moments with loved ones. What is the distribution of devices offering greater than 8MP selfie cameras across brands?
7. Which attributes are highly correlated with the normalized price of a used device?

###Univariate Analysis
"""

#define function to create a histogram and boxplot for univariate analysis

def histogram_boxplot(data, feature, figsize=(15,10), kde=False, bins=None):
  '''
  Combine histogram and boxplot

  data: dataframe
  feature: dataframe column
  figsize: size of figure (default (15,10))
  kde: whether to show density curve (default False)
  bins: number of bins for histogram (default None)
  '''
  f2, (ax_box2, ax_hist2) = plt.subplots(
      nrows=2, #number of rows of subplot grid
      sharex=True, #x-axis will be shared among subplots
      gridspec_kw={"height_ratios": (0.25, 0.75)},
      figsize=figsize #set earlier as default (15,10)
  ) #create 2 subplots for histogram and boxplot
  sns.boxplot(
      data=data, x=feature, ax=ax_box2, showmeans=True, color="violet"
  ) #boxplot will be created and a triangle will show mean value
  sns.histplot(
      data=data, x=feature, kde=kde, ax=ax_hist2, bins=bins
  ) if bins else sns.histplot(
      data=data, x=feature, kde=kde, ax=ax_hist2
  ) #for histogram
  ax_hist2.axvline(
      data[feature].mean(), color="green", linestyle='--'
  ) #mean will be added to histogram with green line
  ax_hist2.axvline(
      data[feature].median(), color="black", linestyle='-'
  ) #median will be added to histogram with black line

#define a function to create labeled barplots

def labeled_barplot(data, feature, perc=False, n=None):
  '''
  Barplot with percentage shown

  data: dataframe
  feature: dataframe column
  perc: whether to display percentages instead of count (default is False)
  n: displays the top n category levels (Default is None to display all levels)
  '''

  total = len(data[feature]) #length of column
  count = data[feature].nunique() #number of unique columns in specified feature
  if n is None:
    plt.figure(figsize=(count+2, 6))
  else:
    plt.figure(figsize=(n+2, 6))

  plt.xticks(rotation=90, fontsize=15)
  ax=sns.countplot(
      data=data,
      x=feature, #x-axis is specified feature
      palette="Paired",
      order=data[feature].value_counts().index[:n],
  )

  for p in ax.patches:
    if perc==True:
      label="{:.1f}%".format(
          100 * p.get_height()/total
      ) #percentage of each class of the category
    else:
      label = p.get_height() #count of each level of the category

    x = p.get_x() + p.get_width()/2 #width of the plot
    y = p.get_height() #height of the plot

    ax.annotate(
        label,
        (x,y),
        ha="center",
        va="center",
        size=12,
        xytext=(0,5),
        textcoords="offset points",
    ) #annotate the percentage

  plt.show() #show the plot

"""We will start with the continuous variables."""

histogram_boxplot(devices, "screen_size")

"""Observations: The screen size variable does not appear to have a normal distribution (right-skewed) and has several outliers."""

histogram_boxplot(devices, "main_camera_mp")

"""Observations: The distribution of the main_camera_mp column appears to be non-normal and has a couple very large outliers."""

histogram_boxplot(devices, "selfie_camera_mp")

"""Observations: The selfie_camera_mp column appears to have a right-skewed distribution with a few outliers."""

histogram_boxplot(devices, "int_memory")

"""Observations: The distribution of the int_memory column is very right-skewed, with a few very large outliers."""

histogram_boxplot(devices, "ram")

devices['ram'].nunique()

"""Observations: The ram column appears to have a large number of values around 4 (as we observed in the statistical summary), with some outliers as well. There are 12 unique values for the ram column."""

histogram_boxplot(devices, "battery")

"""Observations: The distribution of the battery column appears to be slightly right-skewed with a lot of outliers on the higher side of the distribution."""

histogram_boxplot(devices, "weight")

"""Observations: The distribution of the weight column appears very right-skewed with a large amount of outliers on the higher side of the distribution."""

histogram_boxplot(devices, "release_year")

"""Observations: The release_year column's has a distribution closer to uniform than normal and has no outliers, which makes sense as the numbers represent years and not quantities."""

histogram_boxplot(devices, "days_used")

"""Observations: The days_used column appears to have a non-normal and left-skewed distribution with no outliers."""

histogram_boxplot(devices, "normalized_used_price")

"""Observations: The normalized_used_price column appears to have a close to normal distribution with some outliers, particularly on the lower side.

(Question 1: Normal distribution)
"""

histogram_boxplot(devices, "normalized_new_price")

"""Observations: The normalized_new_price column appears to have close to a normal distribution with some outliers. The median and mean appear to be very close in value.

We will now look at the categorical variables.
"""

labeled_barplot(devices, "brand_name")

"""Observations: "Others", "Samsung" and "Huawei" are the 3 top brand names, while "OnePlus", "Google" and "Infinix" are the bottom 3 brand names."""

labeled_barplot(devices, "os", perc=True)

"""Observations: Most phones in the dataset run on Android OS, followed by "Others", Windows, and iOS.

(Question 2: 93.1% of the used device market is dominated by Android devices)
"""

labeled_barplot(devices, "4g", perc=True)

"""Observations: 67.6% of devices in the dataset support 4G."""

labeled_barplot(devices, "5g", perc=True)

"""Observations: 95.6% of phones in the dataset do not support 5G.

###Bivariate Analysis
"""

#we will first look at the correlation between numerical variables with a heatmap

num_cols = devices.select_dtypes(include=np.number).columns.tolist() #create list of numerical columns

plt.figure(figsize=(12,7))
sns.heatmap(devices[num_cols].corr(), annot=True, vmin=-1, vmax=1, fmt=".2f", cmap="Spectral")
plt.show()

"""Observations: Screen size has a high positive correlation with weight and battery, and battery has a high positive correlation to weight as well.

normalized_used_price has a high positive correlation with normalized_new_price, and a moderately high positive correlation (>0.60) with battery and selfie_camera_mp (main_camera_mp is 0.59), and screen size.

Release year has a high negative correlation with days_used and a moderately high positive correlation with selfie_camera_mp (however release year is a value of time and not a quantitative value so we will not get much insight from this column's correlation. We will later deal with this column to be more insightful).

Selfie_camera_mp and days_used have a moderately high negative correlation.

Let's look at how the amount of RAM varies with brand. (Question 3)
"""

#boxplot comparing brand_name and ram
plt.figure(figsize=(12,7))
sns.boxplot(data=devices, x="brand_name", y="ram")
plt.xticks(rotation=90)
plt.show()

#checking the number of unique values in the brand_name column
devices['brand_name'].nunique()

"""Observations: A large amount of the 34 brands have small IQRs around 4 GB. The brands Honor, Infinix, Nokia, OnePlus, Oppo, Realme, Celkon, and Google have ranges above or below 4. Nokia has the lowest RAM ranging between just above 0 to 6, while OnePlus has the largest RAM ranging between 4 and 12.

Now let's look at how weight varies for devices offering large batteries over 4500 mAh. (Question 4)
"""

#create a new dataframe only including devices with batteries over 4500 mAh
large_battery = devices[devices["battery"]>4500]

#boxplot comparing brand_name and weight
plt.figure(figsize=(12,7))
sns.boxplot(data=large_battery, x="brand_name", y="weight")
plt.xticks(rotation=90);

#checking how many devices are in our dataset
large_battery.shape[0]

#checking the mean weight across all devices with a large battery
large_battery['weight'].mean()

"""Observations: There are 341 devices in our dataset with a large battery, and the average weight among all brand names is 332 g. A lot of the brands appear to have an individual average of around 200-250 g, while many other brands have much larger ranges from roughly 200-600 g such as "Others", Lenovo, and Asus. Sony appears to have a range from about 400-500 g.

Now we will look at devices across different brands that have a screen size larger than 6 inches (Question 5).
"""

#first we convert inches to cm (1 inch = 2.54 centimeters)
6 * 2.54

#create a new dataframe with only devices with screens larger than 6 inches, or 15.24 cm
large_screen = devices[devices["screen_size"]>15.24]

#countplot for brand name using the new dataframe for devices with large screens
sns.countplot(data=large_screen, x="brand_name")
plt.xticks(rotation=90);

large_screen.shape[0] #check how many devices have a large screen

avg_large_scrn_size=large_screen["screen_size"].mean() #check mean screen size or larger devices across all brands
avg_large_scrn_size

avg_large_scrn_size/2.54 #convert to inches

"""Observations: Of the 1099 devices in our dataset with a large screen, the average screen size is 17.8 cm (7 inches). Huawei, Samsung, and "Other" brands have the largest amount of devices with a large screen. Microsoft, Panasonic, Spice, XOLO, and Karbonn have the least amount of devices with a large screen.

Now we will look at the distribution of devices offering greater than 8MP selfie cameras across different brands (Question 6).
"""

#create a new dataframe only including devices with 8MP or greater selfie cameras
selfie_8mp = devices[devices["selfie_camera_mp"]>8]

#create boxplot to check distribution of these devices across brands
labeled_barplot(selfie_8mp, "brand_name")

selfie_8mp.shape[0] #checking how many devices have a selfie camera over 8 mp

selfie_8mp['selfie_camera_mp'].mean() #checking mean selfie camera mp of devices over 8 mp across all brands

"""Observations: There are 655 devices with selfie cameras of over 8 mp, the average of which is 18.75 mp. Huawei, Vivo, and Oppo are the brands with the largest amount of deivces with selfie camera mp over 8, while Acer, Panasonic, and Micromax have the smallest amount of devices with selfie camera mp over 8.

Now we will look at which attributes are highly correlated with the normalized price of a used device (Question 7).

According to our heatmap from previously, normalized_used price is the only variable that has over a ~0.5 correlation with this variable.

Regardless, we should take a closer look at the relationship between variables and used device prices.
"""

#create boxplots comparing 4g/5g and used price
sns.boxplot(data = devices, x="4g", y="normalized_used_price")
plt.show()
sns.boxplot(data = devices, x="5g", y="normalized_used_price")
plt.show()

"""Observations: Devices in which 4g is available have an IQR of prices ranging from about 4.25 to 5 euros, while devices that in which 4g is not available have an IQR of prices ranging from about 3.75 to 4.25 euros.

Devices in which 5g is available have an IQR of about 5 to 5.5 euros, while devices that do not have 5g available have an IQR of prices randing from about 4 to 4.75 euros.

Overall, devices which have 5g available have the highest average used price.
"""

#check how the used price of devices varies over the years - we can use a lineplot for looking at changes over time
sns.lineplot(data = devices, x='release_year', y="normalized_used_price", ci=False)
plt.show()

"""Observations: There is an increase in normalized_used price as the years go on. The average used price in 2013 is under 4 euros while the average used price in 2020 is 4.8 euros. However, starting from 2018, the line seems to flatten and prices seem to begin to plateau. However, we would need more data as the years go on to confirm this trend."""

#checking how used price of devices varies with days_used
sns.scatterplot(data = devices, x="days_used", y="normalized_used_price")
plt.show()

"""Observations: There appears to be a a slight negative correlation between days used and normalized_used_price, as to be expected (the more days a phone was used, the lower the cost)."""

#checking how the used price of devices varies with amount of internal memory
sns.scatterplot(data=devices, x="int_memory", y="normalized_used_price")
plt.show()

"""Observations: There does not appear to be a clear correaltion between int_memory and used price. However, there may be a slight positive correlation.

## Data Preprocessing

- Missing value treatment
- Feature engineering (if needed)
- Outlier detection and treatment (if needed)
- Preparing data for modeling
- Any other preprocessing steps (if needed)

First we will treat the missing values in the 6 columns with null values present. We can impute the null values of these columns using the respective median of the brand_name and release year since these appear to be the most relevant grouping metrics.
"""

#copy dataframe to avoid changes to original dataframe we used for original EDA analysis
devices2 = devices.copy()

devices2.isnull().sum() #checking null values again

#create a variable to define a list of the columns with missing values that need to be imputed
cols_na = ["main_camera_mp", "selfie_camera_mp", "int_memory", "ram", "battery", "weight"]

#create for loop to impute these values with the respect grouped-by median
for col in cols_na:
  devices2[col] = devices2[col].fillna(value=devices2.groupby(['brand_name','release_year'])[col].transform("median"))

#check whether there are any additional missing values
devices2.isnull().sum()

"""Since we still have some missing values, we can impute the remaining using the median grouped by brand_name as this is likely the most accurate categorical attribute to impute our data with."""

#impute remaining missing values in the data using the respective median grouped by brand_name
cols_na_2 = ["main_camera_mp", "selfie_camera_mp", "battery", "weight"]

#create similar for loop as above
for col in cols_na_2:
  devices2[col] = devices2[col].fillna(value=devices2.groupby(['brand_name'])[col].transform("median"))

#check again for remaining missing values
devices2.isnull().sum()

"""We can impute the last remaining values in the main_camera_mp column by using the column's own median."""

devices2['main_camera_mp'] = devices2['main_camera_mp'].fillna(devices2['main_camera_mp'].median())

#check if remaining null values were imputed
devices2.isnull().sum()

"""All null observations have been imputed.

As mentioned during the heatmap analysis, the release_year column values represent a year and not a quantity. In order to turn this column into numerical data that can be analyzed the same way as the other attributes, we can create a new column in the dataframe showing the number of years since the device was released. We can do this by subtracting the year the data was collected (2021) by the release_year.
"""

devices2['years_released'] = 2021 - devices2['release_year'] #create new column showing number of years the device has been out
devices2.drop('release_year', axis=1, inplace=True) #drop the release_year column

devices2.head() #check to make sure these changes were executed properly

"""We will now check for outliers in the data using boxplots"""

num_cols = devices2.select_dtypes(include=np.number).columns.tolist() #create list of columns with continuous data type

plt.figure(figsize=(12,7))
for i, variable in enumerate(num_cols):
  plt.subplot(3,4,i+1)
  sns.boxplot(data=devices2, x=variable)
  plt.tight_layout(pad=2)

plt.show()

"""Outliers are present in almost all the columns.

The two columns which contain outliers that look most out of place are int_memory and ram. The other columns (based on both univariate and bivariate analysis) appear to have outliers that are real values, in that there are multiple outliers close together, indicating these are not errors.

For these two columns, we will look at the amount of values outside a chosen value to determine how likely it is that these outliers were a mistake versus a real data point. If there are only 1 or a few data points at these more extreme numbers, we may conclude that these outliers are an error, or we may determine they should be removed because they skew our dataset.

Note that removing outliers can result in loss of information.
"""

#checking the number of devices with a int_memory of over 400
devices2[devices2['int_memory']>500].count().sum()

#checking number of devices with an int_memory over 600
devices2[devices2['int_memory']>600].count().sum()

"""It appears that there are enough values shown as outliers on the boxplot that we can consider these real values (in other words, and internal memory of 1000 GB is a legitimate measure). We do not need to treat missing values for this column.

"""

#checking the number of devices with a ram of over 10
devices2[devices2['ram']>10].count().sum()

"""It appears that there are enough values shown as outliers on the boxplot that we can consider these real values. We do not need to treat missing values for this column.

## EDA

- It is a good idea to explore the data once again after manipulating it.
"""

#we will look at correlation again
cols = devices2.select_dtypes(include=np.number).columns.tolist()

plt.figure(figsize=(12,7))
sns.heatmap(devices2[cols].corr(), annot=True, vmin=-1, vmax=1, fmt=".2f", cmap="Spectral")
plt.show()

"""Observations: We notice that the number of years since release (a new column since the last analysis) has a high positive correlation with days_used, as expected, and a fairly strong negative correlation with selfie_camera_mp.

We will now recheck the distributions of the columns for which we imputed values, as well as the years_released column.
"""

histogram_boxplot(devices2, 'years_released')

"""Observations: This column has a distribution closer to uniform than normal, and values range from 1 to 8 years."""

#checking distribution of the main_camera_mp column
histogram_boxplot(devices2, 'main_camera_mp')

histogram_boxplot(devices2, 'selfie_camera_mp')

histogram_boxplot(devices2, 'int_memory')

histogram_boxplot(devices2, 'ram')

histogram_boxplot(devices2, 'battery')

histogram_boxplot(devices2, 'weight')

"""Observation: The histograms and boxplots look very similar to our original analysis.

###Data Preparation for Modeling
"""

#define X and Y variables
X = devices2.drop(["normalized_used_price"], axis=1) #all columns but normalized_used_price are the independent variables
Y = devices2['normalized_used_price']

print(X.head())
print(Y.head())

#add the intercept to the data
X = sm.add_constant(X)

#Creating dummy variables for categorical columns
X = pd.get_dummies(X, columns = X.select_dtypes(include=["object"]).columns.tolist(), drop_first=True)
#dropfirst will drop the first dummy variable in alphabetical order for a given column
X.head()

#splitting the data in 70:30 ratio for train and test data

X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.3, random_state=1)

print("Number of rows in train data =", X_train.shape[0])
print("Number of rows in test data =", X_test.shape[0])

"""## Model Building - Linear Regression"""

olsmodel = sm.OLS(Y_train, X_train).fit()
print(olsmodel.summary())

"""Observations:

- The Adjusted R-squared is 0.84 , which means it explains 84% of variance in the data. This is considered a good Adjusted R-squared value.

- The Y-intercept is equal to 1.3156, meaning that if all the predictor variable coefficients were zero, the expected normalized used price is equal to this number.

- Coefficient of predictor variables: An example is the coefficient of screensize which 0.0244. This means that with one unit increase in screensize, the output (Y) would increase by 0.0244.

## Model Performance Check

We will now check the model's performance using five different metrics: RMSE, MAE, MAPE, R-squared and adjusted R-squared.  We will do this by defining a function to calculate and print these metrics for our model.
"""

#define function to compute adjusted R-squared
def adj_r2_score(predictors, targets, predictions):
  r2 = r2_score(targets, predictions)
  n = predictors.shape[0]
  k = predictors.shape[1]
  return 1 - ((1-r2) * (n-1) / (n-k-1))

#define function to compute MAPE
def mape_score(targets, predictions):
  return np.mean(np.abs(targets - predictions) / targets) * 100

#define function to compute RMSE, MAE, R-squared, Adjusted R-squared, and MAPE and compile into a signel dataframe
def model_performance_regression(model, predictors, target):
  '''
  Function to compute metrics to check regression model performance

  model: regressor
  predictors: independent variables
  target: dependent variable
  '''

  #prediction using the independent variables
  pred = model.predict(predictors)

  r2 = r2_score(target, pred) #compute R-squared value
  adjr2 = adj_r2_score(predictors, target, pred) #compute adjusted R-squared value
  rmse = np.sqrt(mean_squared_error(target, pred)) #compute MAE
  mae = mean_absolute_error(target, pred) #compute MAE
  mape = mape_score(target, pred) #compute MAPE

  #creating dataframe of performance metrics
  df_perf = pd.DataFrame(
      {
        "RMSE": rmse,
        "MAE": mae,
        "R-squared": r2,
        "Adj. R-squared": adjr2,
        "MAPE": mape,
      },
      index=[0],
  )

  return df_perf

#checking our model performance on the train set
print("Training Performance\n")
olsmodel_train_perf = model_performance_regression(olsmodel, X_train, Y_train)
olsmodel_train_perf

#checking model performance on the test set
print("Test Performance\n")
olsmodel_test_perf = model_performance_regression(olsmodel, X_test, Y_test)
olsmodel_test_perf

"""Observations:

- The training R2 value is 0.84, so we know the model is not underfitting

- The train and test RMSE and MAE are close, so we know the model is not overfitting either

- The MAE shows that the model can predict the normalized used price of devices within a mean error of 0.18 on the test data

- The MAPE of 4.5 on the test data means that we are able to predict within 4.5% of the normalized used price. This is very good.

## Checking Linear Regression Assumptions

In order to make statistical inferences from a linear regression model, it is important to ensure that the assumptions of linear regression are satisfied.

We will first check for multicollinearity using VIF. We are looking for VIF values over 5 (moderate correlation)
"""

#define function to check VIF

from statsmodels.stats.outliers_influence import variance_inflation_factor #import required library

def checking_vif(predictors):
  vif = pd.DataFrame()
  vif["feature"] = predictors.columns

  #calculating VIF for each feature
  vif["VIF"] = [
      variance_inflation_factor(predictors.values, i)
      for i in range(len(predictors.columns))
  ]
  return vif

#we will check the VIF values on the train data
checking_vif(X_train)

"""Observations:

The weight and screen size columns have a higher VIF (over 5 to indicate moderate multicollinearity). Note that the VIF for the constant and dummy variables can be ignored.

We will drop these columns one at a time and look at the adjusted R-squared and RMSE of the resulting model, and drop the variable that makes the least change in the adjusted R-squared variable (and therefore has the least effect on the model.
"""

#define function to drop every column with a VIF score greater than 5 and show the Adjusted R-squared and RMSE after dropping each column

def treating_multicollinearity(predictors, target, high_vif_columns):
  '''
  Checking the effect of dropping the columns showing high multicollinearity on model performance.

  predictors: independent variables
  target: dependent variable
  high_vif_columns: columns having high VIF
  '''
  #empty lists to store adjusted R-squared and RMSE values
  adj_r2 = []
  rmse = []

  #build ols models by dropping one of the high VIF columns at a time
  #store adjusted R-squared and RMSE in the lists defined above
  for cols in high_vif_columns:
    #defining the new train set
    train = predictors.loc[:, ~predictors.columns.str.startswith(cols)]

    #create the model
    olsmodel = sm.OLS(target, train).fit()

    #adding adjusted R-dquared and RMSE to the lists
    adj_r2.append(olsmodel.rsquared_adj)
    rmse.append(np.sqrt(olsmodel.mse_resid))

  #creating a dataframe for the results
  temp = pd.DataFrame(
      {
          "col": high_vif_columns,
          "Adj. R-squared after dropping col": adj_r2,
          "RMSE after dropping col": rmse,
      }
  ).sort_values(by="Adj. R-squared after dropping col", ascending=False)
  temp.reset_index(drop=True, inplace=True)

  return temp

high_vif_cols = ['screen_size', 'weight']

res = treating_multicollinearity(X_train, Y_train, high_vif_cols)
res

"""Observations: The adjusted R-squared column did not drop by much in either case. However, the screen_size column resulted in a slightly lower drop in adjusted R-squared value. Therefore, we will drop this column, as it has a slightly smaller affect on the model compared to weight."""

col_to_drop = "screen_size"
X_train2 = X_train.loc[:, ~X_train.columns.str.startswith(col_to_drop)]
X_test2 = X_test.loc[:, ~X_test.columns.str.startswith(col_to_drop)]

#checking VIF after dropping screen size column
vif = checking_vif(X_train2)
print("VIF after dropping ", col_to_drop)
vif

"""Observations: All the remaining columns (except for the constant and dummy variables) have a VIF of under 5. We have effectively dealt with multicollinearity in the data.

We will now rebuild the model using the updated set of predictor variables.
"""

olsmod1 = sm.OLS(Y_train, X_train2).fit()
print(olsmod1.summary())

"""Observations:

- The adjusted R-squared value have dropped to 0.838, showing the dropped column did not have much effect on the model.
- We can now look at the p-values of the predictor variables to check their significance.

We will define a function to build a model, check the p-values of the variables, drop the column with the highest p-value, and repeat these steps until there are no columns with a p-value above 0.05 (the chosen level of significance).
"""

#creating a while loop to take a value with a high p-value, dropping it, and building another model

#initial list of columns
predictors = X_train2.copy()
cols = predictors.columns.tolist()

#setting initial max p-value
max_p_value = 1

while len(cols) > 0:
  #define train set
  X_train_aux = predictors[cols]

  #fitting the model
  model = sm.OLS (Y_train, X_train_aux).fit()

  #getting the p-values and maximum p-value
  p_values = model.pvalues
  max_p_value = max(p_values)

  #name of variable with maximum p-value
  feature_with_p_max = p_values.idxmax()

  if max_p_value > 0.05:
    cols.remove(feature_with_p_max)
  else:
    break

selected_features = cols
print(selected_features)

"""Observations: The list output shown above are the columns remaining in the model."""

#create new test and train set with the selected columns from the above loop after dropping high p-value columns
X_train3 = X_train2[selected_features]
X_test3 = X_test2[selected_features]

#creating a model with the new test and train set
olsmod2 = sm.OLS (Y_train, X_train3).fit()
print(olsmod2.summary())

#check model performance on train set
print("Training Performance\n")
olsmod2_train_perf = model_performance_regression(olsmod2, X_train3, Y_train)
olsmod2_train_perf

#checking model performance on test set
print("Test Performance\n")
olsmod2_test_perf = model_performance_regression(olsmod2, X_test3, Y_test)
olsmod2_test_perf

"""Observations:

- Now no feature has a p-value greater than 0.05.

- The adjusted R-squared value is 0.838, showing that the variables dropped were not affecting the model.

- The RMSE and MAE valuable are comparable for the train and test sets, showing that the model is not overfitting.

We will now check the rest of the assumptions on olsmod2:

- linearity of variables
- independence of residuals
- normality of residuals
- homoscedasticity

We will first check for linearity and independence by plotting the fitted values against the residuals and seeing if there is a pattern. If there is no pattern, we can assume the model is linear. If there is a pattern, the model is showing signs of non-linearity and the residuals are dependent.
"""

#create a dataframe with the actual values, fitted values, and residual values

df_pred = pd.DataFrame() #create empty dataframe

df_pred["Actual Values"] = Y_train
df_pred["Fitted Values"] = olsmod2.fittedvalues
df_pred["Residuals"] = olsmod2.resid

df_pred.head()

#plot predicted values vs residuals

def residplot(data): #define a function so that we can repeat this plot later if needed

  sns.residplot(data=data, x="Fitted Values", y="Residuals", color="purple", lowess=True)
  plt.show()

residplot(df_pred)

"""We see no pattern, and can assume the model is both linear and that the residuals are independent.

Now we can check the assumption of normality of the residuals using histogram of the residuals.
"""

sns.histplot(data=df_pred, x="Residuals", kde=True)
plt.show()

"""Observations: The distribution appears slightly left-skewed, though relatively close to normal.

We can check the Q-Q plot to check further for normality.
"""

import pylab
import scipy.stats as stats

stats.probplot(df_pred["Residuals"], dist="norm", plot=pylab)
plt.show()

"""Observations:

The residuals follow a relatively straight line except for the tails.

We can check the results of the Shapiro-Wilk test as well.
"""

stats.shapiro(df_pred["Residuals"])

"""Since the p-value is < 0.05, the distribution is not considered normal technically-speaking. However, based on the distribution and Q-Q plot, we can accept that the distribution is close to normal, and the assumption is satisfied.

Finally, we can test for homoscedasticity (or, lack of heteroscedasticity.

We can first use the residuals vs fitted values plot to check for an arrow or other asymmetrical shape which would indicate heteroscedasticity.
"""

#checking the plot again
residplot(df_pred)

"""Observations: Overall, the plot looks homoscedastic. There may be a slightly higher variance on the lower (left) end of the plot.

We can check the goldfeldquandt test next. As the null hypothesis is that the residuals are homoscedastic, if we get a p value of over 0.05, we can assume the residuals are homoscedastic.
"""

import statsmodels.stats.api as sms
from statsmodels.compat import lzip

name=["F statistic", "p_value"]
test = sms.het_goldfeldquandt(df_pred["Residuals"], X_train3)
lzip(name, test)

"""Observations: The p-value is over 0.05, so the assumption for homoscedasticity is satisfied.

All of the linear regression assumptions are satisfied, and we can proceed with the final model. We will first create predictions based on our current version of the model.
"""

#predictions on the test set
pred = olsmod2.predict(X_test3)
df_pred_test = pd.DataFrame({"Actual": Y_test, "Predicted": pred})
df_pred_test.sample(10, random_state=1)

"""The actual and predicted values are comparable, indicating that our model is doing a good job of predicting values.

Let's move forward with our final model.

## Final Model
"""

X_train_final = X_train3.copy()
X_test_final = X_test3.copy()

olsmodel_final = sm.OLS (Y_train, X_train_final).fit()
print(olsmodel_final.summary())

"""We will now check the final model's performance on the train set."""

print("Training Performance\n")
olsmodel_final_train_perf = model_performance_regression(olsmodel_final, X_train_final, Y_train)

olsmodel_final_train_perf

"""Now we will check the final model's performance on the test set."""

print("Test Performance\n")
olsmodel_final_test_perf = model_performance_regression(olsmodel_final, X_test_final, Y_test)

olsmodel_final_test_perf

"""Observations:

- Based on the adjusted R-squared value, the model is able to explain around 84% of variation in the data. This tells us that our model is not underfitting.

- The RMSE and MAE for the test data are quite low and also close in value to the train data RMSE and MAE. This tells us that our model is not overfitting.

- The MAPE on the test set tells us that the model can predict within  4.6% of the prices, which is very good.

- We can conclude that the final model is good for prediction and inference.

## Actionable Insights and Recommendations

- The model is good for prediction and inference purposes:
    - The model is able to explain around 84% of the variation in the data
    - The model can predict within 4.6% of the prices on the test data.

- The model gives us the following relationships regarding other variables relating to predicted normalized used price:
  - The price will increase by 0.021 euros with one increase in the main camera megapixels
  - The price will increase by 0.138 euros with one increase in the selfie camera megapixels
  - The price will increase by 0.0207 euros for every one unit increase in ram
  - The price will increase by 0.0017 euros for every one gram increase in weight.
  - The price will *decrease* by 0.0292 euros as the amount of years since the products release increases by one year (the longer the product has been out, the lower the price).

- The company can gather data about their users such as purpose of the device (work, recreation, etc), occupation, age, and gender to better understand and market devices to different users.

- As the price increases with the devices cameras megapixels, the company can market devices with higher resolution cameras to target audiences that have a greater need for camera use (photographers, influencers, etc).

- The same can be said for the increase in price as ram in GB increases. Targeted marketing to demographics that would need higher RAM on their devices such as people that work using their device or use a lot of apps.

- The company can market newer devices as price decreases with years since release.

___
"""